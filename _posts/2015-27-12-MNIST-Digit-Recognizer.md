---
layout: post
title: Data science monthly write-up--MNIST digit recognition Kaggle competition
---

#Introduction
In this post I'll write about my attempt at the [digit recognition Kaggle competition](https://www.kaggle.com), using machine learning to recognize different digitalized hand written numbers. This was my first foray into solving a data-sciency problem on my own (i.e., not as part of a class), so I didn't expect a great score starting out. In fact, the two methods I employed probably aren't the best for the job, and I didn't want to use any pre-existing packages. Of course, there are packages out there that could probably score me a 99% on the recognition test in just a few lines of my own code, but that's not the point. 

To solve the challenge, I tried two different solutions. The first solution uses an algorithm called [dynamic time warping](https://en.wikipedia.org/wiki/Dynamic_time_warping) and the second solution uses [soft-max regression](), a generalization of logistic regression to allow for multiple classifications. I'll do my best to explain how each method works, summarize the code that I wrote to run the method, and finally discuss the results of each method.

#Dynamic time warping



#Soft-max regression (~logistic regression)



The easiest way to make your first post is to edit this one. Go into /_posts/ and update the Hello World markdown file. For more instructions head over to the [Jekyll Now repository](https://github.com/barryclark/jekyll-now) on GitHub.